{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bff58b1",
   "metadata": {},
   "source": [
    "### Use CV to scan the face, read the data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Description: Recognize faces and determine fatigue by analyzing yawning and blinking frequencies. Special cases like singing with a wide-open mouth or getting sand in the eyes should be avoided; both criteria need to be met to trigger an alarm.\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import mysql.connector\n",
    "import time\n",
    "import paramiko\n",
    "\n",
    "# MySQL Database Configuration\n",
    "mysql_config = {\n",
    "    'host': '192.168.137.203',\n",
    "    'database': 'fatigueTest',\n",
    "    'user': 'root',\n",
    "    'password': 'tansome'\n",
    "}\n",
    "\n",
    "# Clear the database table\n",
    "def clear_table(cursor):\n",
    "    # Query the latest ten records\n",
    "    select_query = 'SELECT * FROM nap ORDER BY time DESC LIMIT 10'\n",
    "    cursor.execute(select_query)\n",
    "    latest_data = cursor.fetchall()\n",
    "    \n",
    "    # Clear the table\n",
    "    cursor.execute('TRUNCATE TABLE nap')\n",
    "    \n",
    "    # Reinsert the latest ten records into the table\n",
    "    insert_query = 'INSERT INTO nap (time, blink, yawn) VALUES (%s, %s, %s)'\n",
    "    for data in latest_data:\n",
    "        cursor.execute(insert_query, data)\n",
    "\n",
    "    \n",
    "# Add data to the database table\n",
    "def add_data(cursor, time_value, blink_value, yawn_value):\n",
    "    insert_query = 'INSERT INTO nap (time, blink, yawn) VALUES (%s, %s, %s)'\n",
    "    cursor.execute(insert_query, (time_value, blink_value, yawn_value))\n",
    "\n",
    "# Connect to the MySQL database\n",
    "connection = mysql.connector.connect(**mysql_config)\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Clear the database table\n",
    "clear_table(cursor)\n",
    "\n",
    "# First, automatically enable SSH and start the camera\n",
    "# SSH connection information\n",
    "hostname = '192.168.137.240'  # Raspberry Pi's IP address\n",
    "port = 22  # SSH port number, default is 22\n",
    "username = 'wwb'  # Raspberry Pi's username\n",
    "password = 'pi'  # Raspberry Pi's user password\n",
    "\n",
    "# Create an SSH client object\n",
    "client = paramiko.SSHClient()\n",
    "client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "try:\n",
    "    # Connect to the Raspberry Pi\n",
    "    client.connect(hostname, port, username, password)\n",
    "    \n",
    "    # Execute the \"sudo motion\" command\n",
    "    stdin, stdout, stderr = client.exec_command('sudo motion')\n",
    "\n",
    "    # Get the command execution result\n",
    "    output = stdout.read().decode('utf-8')\n",
    "    print(output)\n",
    "    \n",
    "    # Close the SSH connection\n",
    "    client.close()\n",
    "\n",
    "except paramiko.AuthenticationException:\n",
    "    print(\"Authentication failed. Please check the username and password.\")\n",
    "\n",
    "except paramiko.SSHException as ssh_err:\n",
    "    print(\"SSH connection error:\", ssh_err)\n",
    "\n",
    "except paramiko.Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Define the URL of the video source\n",
    "url = \"http://192.168.137.240:8081/\" # Raspberry Pi 2, used for capturing facial fatigue values\n",
    "# # url = \"http://mirror.aarnet.edu.au/pub/TED-talks/911Mothers_2010W-480p.mp4\" # For testing purposes\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(url)\n",
    "\n",
    "# Check if the video capture object was opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Unable to open the video source\")\n",
    "    exit()\n",
    "\n",
    "# Define facial landmarks\n",
    "FACIAL_LANDMARKS_68_IDXS = dict([\n",
    "    (\"mouth\", (48, 68)),\n",
    "    (\"right_eyebrow\", (17, 22)),\n",
    "    (\"left_eyebrow\", (22, 27)),\n",
    "    (\"right_eye\", (36, 42)),\n",
    "    (\"left_eye\", (42, 48)),\n",
    "    (\"nose\", (27, 36)),\n",
    "    (\"jaw\", (0, 17))\n",
    "])\n",
    "\n",
    "# Function to calculate eye aspect ratio (ear)\n",
    "def eye_aspect_ratio(eye):\n",
    "    # Calculate distances vertically\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    # Calculate distances horizontally\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # Calculate ear value\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Function to calculate mouth aspect ratio (mou)\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    # Calculate distances vertically\n",
    "    D = dist.euclidean(mouth[3], mouth[18])\n",
    "    E = dist.euclidean(mouth[14], mouth[9])\n",
    "    # Calculate distances horizontally\n",
    "    F = dist.euclidean(mouth[0], mouth[6])\n",
    "    # Calculate mou value\n",
    "    mou = (D + E) / (2.0 * F)\n",
    "    return mou \n",
    "\n",
    "# Function to convert shape object to NumPy array\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # Create a 68x2 NumPy array\n",
    "    coords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
    "    # Traverse each landmark\n",
    "    # Get the coordinates\n",
    "    for i in range(0, shape.num_parts):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "    return coords\n",
    "\n",
    "# Set threshold parameters (needs tuning)\n",
    "EYE_AR_THRESH = 0.3  # If ear is less than 0.3, it is considered as blinking\n",
    "EYE_AR_CONSEC_FRAMES = 3  # If the ear is less than 0.3 for three consecutive frames, it is considered as a blink\n",
    "MOU_AR_THRESH = 0.4  # If mou is greater than 0.5, it is considered as yawning\n",
    "MOU_AR_CONSEC_FRAMES = 10  # If mou is greater than 0.5 for ten consecutive frames, it is considered as yawning\n",
    "\n",
    "# Initialize counters\n",
    "COUNTER_ear = 0\n",
    "COUNTER_mou = 0\n",
    "TOTAL_ear = 0\n",
    "TOTAL_mou = 0\n",
    "start_time = time.time()\n",
    "\n",
    "# Load the face detection and facial landmark model from dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('.\\shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Get the regions for both eyes\n",
    "(lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n",
    "(mStart, mEnd) = FACIAL_LANDMARKS_68_IDXS[\"mouth\"]\n",
    "\n",
    "# Continuously loop to detect and output results\n",
    "while True:\n",
    "    \n",
    "    # Check if 30 seconds time interval has been reached\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    if elapsed_time >= 30:\n",
    "        # Insert the data into the MySQL database\n",
    "        add_data(cursor,current_time,TOTAL_ear,TOTAL_mou)\n",
    "        # Commit the database transaction\n",
    "        connection.commit()\n",
    "\n",
    "        # Reset counters and time variable\n",
    "        TOTAL_ear = 0\n",
    "        TOTAL_mou = 0\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Read a video frame\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 0)\n",
    "    # Resize the camera image to reduce computations\n",
    "    frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    \n",
    "    # Check if the frame was read successfully\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve video frame\")\n",
    "        break\n",
    "        \n",
    "    (h, w) = frame.shape[:2]\n",
    "    width=1200\n",
    "    r = width / float(w)\n",
    "    dim = (width, int(h * r))\n",
    "    frame = cv2.resize(frame, dim, interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    # Detect faces\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # Loop over each detected face\n",
    "    for rect in rects:\n",
    "        # Get the facial landmarks\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "\n",
    "        # Calculate ear and mou values\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        mouth = shape[mStart:mEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        mou = mouth_aspect_ratio(mouth)\n",
    "\n",
    "        # Calculate the average ear value\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "        # Draw eye regions\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 0, 255), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 0, 255), 1)\n",
    "\n",
    "        # Draw mouth region\n",
    "        mouthHull = cv2.convexHull(mouth)\n",
    "        cv2.drawContours(frame, [mouth], -1, (0, 0, 255), 1)     \n",
    "        \n",
    "        # Check if ear meets the threshold\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER_ear += 1\n",
    "\n",
    "        else:\n",
    "            # If ear is less than 0.3 for several consecutive frames, count as a blink\n",
    "            if COUNTER_ear >= EYE_AR_CONSEC_FRAMES:\n",
    "                TOTAL_ear += 1\n",
    "\n",
    "            # Reset the counter\n",
    "            COUNTER_ear = 0\n",
    "\n",
    "        # Check if mou meets the threshold\n",
    "        if mou > MOU_AR_THRESH:\n",
    "            COUNTER_mou += 1\n",
    "\n",
    "        else:\n",
    "            # If mou is greater than 0.5 for several consecutive frames, count as yawning\n",
    "            if COUNTER_mou >= MOU_AR_CONSEC_FRAMES:\n",
    "                TOTAL_mou += 1\n",
    "\n",
    "            # Reset the counter\n",
    "            COUNTER_mou = 0            \n",
    "            \n",
    "        # Display the results\n",
    "        cv2.putText(frame, \"Blinks: {}\".format(TOTAL_ear), (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Yawns: {}\".format(TOTAL_mou), (10, 60),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"MOU: {:.2f}\".format(mou), (300, 60),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)        \n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "    \n",
    "    # Press 'q' key to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        # Close the cursor and database connection\n",
    "        cursor.close()\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
